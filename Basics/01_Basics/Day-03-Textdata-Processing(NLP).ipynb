{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f9c9a-f362-499e-a883-e705cd0f02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b80f22-fbf7-49a6-a9e4-fb760364ab8e",
   "metadata": {},
   "source": [
    "## Text Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e24f8c-d891-4960-b905-4a56a882e08a",
   "metadata": {},
   "source": [
    "- Text data preprocessing is the process of transforming raw textual data into a clean, structured, and machine-understandable format.\n",
    "- It is the first and most important step in any NLP (Natural Language Processing) workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17dfd6f-5dbe-4a74-8798-8d24da2ae680",
   "metadata": {},
   "source": [
    "- Binary bag of words or OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796f48e-72f3-4175-ada6-54b494e77aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab16f4-f086-4ef0-953f-5612c43e7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"rahul likes to watch movies. priya likes movies too\" ,\"rahul also likes to watch cricket matches\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb64bde-e0f9-4cad-8757-f40447546a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(binary=True)\n",
    "cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218e086-4c31-4e85-bcd8-a35627ae37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c4241-4804-4023-bc45-9459d0eaa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cvec.fit_transform(documents).toarray(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb2b15-4b3a-4880-94e3-9b8a8dfa7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[\"all costly products after better functionality\",\"all products after better functionality costly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38feb278-0bf0-4f2c-a8db-55986883c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec.fit_transform(d).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ad924-3153-4b35-9920-fbba9b13684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3075f07-09b0-4e99-9955-d9f7bd8b88e9",
   "metadata": {},
   "source": [
    "- Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfa731-e1c5-40c9-8186-7db59a20eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cfd66-b6e2-4982-8728-048ef8716149",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect=CountVectorizer()\n",
    "cvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbafe7-7b14-434d-9c90-ebd012e86cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[\"rahul likes to watch movies. priya likes movies too\" ,\"rahul also likes to watch cricket matches\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7422b-18a4-4d86-8eca-ea6a3d3c25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d7fd0-490d-4093-bafd-b1f8d4a4c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cvect.fit_transform(documents).toarray(),columns=cvect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2807e1-910d-4f97-afe2-8fc2ed766481",
   "metadata": {},
   "source": [
    "- TFI-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a417b-a572-458d-9401-4a7b0771e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=[\"The dog plays with the ball\",\"The cat plays with the ball\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb545f-a83b-4c45-a009-255a979554af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb43e7-4ba1-4121-9d5d-8344ade83ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffbca6-3b4e-4709-b412-17752acbb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit_transform(doc).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccff71-57c6-4ecd-ae1a-1de7205e203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tfidf.fit_transform(doc).toarray(),columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def4d5b-dc62-4b9d-8142-825004d1ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77d4c2-13f1-4b31-b42b-d3317b013e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5d5bf-32ba-4400-b61d-9354bfbda833",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tfidf.fit_transform(documents).toarray(),columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8908f21-bdff-4eac-ba60-4bb0e657e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ce23c-aa50-4855-b5cf-60d515ef3c7f",
   "metadata": {},
   "source": [
    "n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bec6b-9382-4032-b6ed-591f71c2d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58dad93-9c3b-4ed0-b133-66f9e9b9783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece0860-d4ce-4b72-a26c-f151c3c0c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee050d7b-4ae5-480e-b6d8-64ce795720fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99c515-e597-452a-90d5-cca642875010",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4148cec-b9f0-48f6-abb3-ff2f93a50e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tfidf.fit_transform(documents).toarray(),columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612a47b-185f-4377-b4e1-3eb61d7d88c2",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1c1a6-c775-4f53-ba24-c942f51d8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\HP\\Downloads\\email_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55b14d-7fdb-4731-ad21-0e1ab246b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a00e-7bfe-4235-9fb2-7cea6f9e5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ba008-2548-4050-9485-f540c5f66ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d510707-9196-4374-bec7-ee5f418ace84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e93c00-f299-4df8-b4de-d30a67e4d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "pattern=r\"[^\\w\\s]\"\n",
    "re.sub(pattern,'',doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286e552-3cbd-4e05-9afe-6e4ded586459",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af3ec2-9e79-4cab-a1be-a7e11324bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27329946-a967-4717-9834-7979d20b0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[token for token in doc.split() if token not in string.punctuation]\n",
    "doc1=' '.join(tokens)\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80036151-2798-4656-9108-0689ae8cd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc1.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae55d12-1255-415f-ac81-09652ecc161e",
   "metadata": {},
   "source": [
    "- cannot=can't,do not=don't / not impact on visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0331e-5109-47a6-9562-6e64826a8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b50b7b-9d9a-4753-bb16-ccb59f5f8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a092335-ccf5-45cb-9313-a2c319c0c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(\"can't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111043d-a6ad-4e7a-b939-9b151aaa12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions.fix(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aee001-5065-4412-943d-557ca539ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd4a04-6f4f-4ed8-bcc9-f915e9c4ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob   # Computational complex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637eaed-3568-4ab2-b612-d68ef21cc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=TextBlob('betwein')\n",
    "obj.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6483e9d-7fcb-40cc-bb38-6cec65f43477",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(obj.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322cd8e-b337-4888-bf2f-5a5ca066cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bee5bc-0e0a-49f9-95f8-8cf28f13712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892931b-b4ac-4966-847e-5a5bd46bf012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6ca68-c5ae-4131-a7f9-309a16c3d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41264304-d49c-44d2-b4d9-d826cf004a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[token for token in doc1.split() if token not in stopwords.words('english')]\n",
    "doc1=' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7af04e-7a8c-4d6c-b9c2-4b4391c29fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765ca83-2be1-453a-ba04-5b0c16483538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331606e7-db6b-439c-8ef6-f9e041e8b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d001b80-72ec-4f1b-9d3f-26ad1be952d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8f818-2256-4f71-a275-28f041d98e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1186330-687c-4860-bd4e-dda19d1fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pstemmer = PorterStemmer()\n",
    "pstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516ecf8-eeee-4d0f-9d26-2f47047d0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "pstemmer.stem('likely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5496ebe-5e90-45f4-a151-acb583951ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pstemmer.stem('university')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a65e8c-5b19-44cf-abfb-60f9b4d9ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pstemmer.stem('closely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df8df4-d4df-46c5-a20f-d96522f1726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstemmer = SnowballStemmer('english')\n",
    "sstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084b0c5-6da8-4b8c-806f-18491151c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstemmer = LancasterStemmer()\n",
    "lstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453eadfc-fde9-41e7-a1bb-2777681196d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstemmer.stem('closely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335d540-e7c0-48e0-9da0-7bded6d354e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstemmer.stem('university')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012c805-6be0-4eab-8b32-be72311b7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a603faa-b238-4ec5-adbc-05a76ed801f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5c3f4-2253-4124-839d-799a2b651d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0b5b9-d102-4f2c-b1a5-6a39153ad991",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('closely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2570d5c-511e-4df4-98df-ca46cd354fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('closely', wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec66cf0-9adb-4a43-9804-d60b06e6135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('went', wordnet.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ed915-cb14-449c-9c9f-6071d5e4f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('university', wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3be02-c19b-4a83-9d66-d5c2b7519c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tag\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386a91d-00dd-4724-bbfd-272a4ff7b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80ffc1-c119-4c82-bf17-dbd5177767b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(['went'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38724b-00a9-4d6d-b989-a345a5f3827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(['university'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1ec69-d390-4c48-aa2d-31b65bbe59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordnet_pos(word):\n",
    "  tag = pos_tag([word])[0][1][0]\n",
    "  tag_dict = {'N': wordnet.NOUN,\n",
    "              'V': wordnet.VERB,\n",
    "              'J': wordnet.ADJ,\n",
    "              'R': wordnet.ADV}\n",
    "  return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e81e5-fea1-4c1a-99a5-1fc122ae5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_pos('closely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd50f1e-50ea-4040-adab-6a025ea68aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'went'\n",
    "lemmatizer.lemmatize(word, wordnet_pos(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602756ff-db0d-457a-88f6-eda942987fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import contractions\n",
    "except:\n",
    "  !pip install contractions\n",
    "  import contractions\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc, stem = False):\n",
    "    # 1. Correct shortforms\n",
    "    doc = contractions.fix(doc)\n",
    "\n",
    "    # 2. Clean the text using regex\n",
    "    regex = r'[^a-zA-Z]'\n",
    "    doc = re.sub(regex, ' ', doc)\n",
    "\n",
    "    # 3. Correct Spelling\n",
    "    blob = TextBlob(doc)\n",
    "    doc = str(blob.correct())\n",
    "\n",
    "    # 4. Convert to lower case\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # 5. Tokenize the text\n",
    "    tokens = word_tokenize(doc)\n",
    "\n",
    "    # 6. Removal of punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # 7. Removal of stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    # 8. Stemming or Lemmatization\n",
    "    if stem:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    else:\n",
    "        tokens = [lemmatizer.lemmatize(token, wordnet_pos(token)) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f406f-e9cf-4797-a7c5-d0c1c8a5c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df.loc[1, 'text']\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f6253-c2d6-4420-8464-8b987f665c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa72a7b-8898-44e6-b186-5fa48a8cc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d07f1-6dbb-43db-9502-5b199cf9a927",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = df.loc[:100, 'text']\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b9ed0-1350-4f2e-82fe-45e840324649",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new['clean_text'] = df['text'].apply(clean)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918bea51-f5ba-4a9c-8c3d-38d1d8435216",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import contractions\n",
    "except:\n",
    "  !pip install contractions\n",
    "  import contractions\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc, stem = True):\n",
    "    # 1. Correct shortforms\n",
    "    # doc = contractions.fix(doc)\n",
    "\n",
    "    # 2. Clean the text using regex\n",
    "    regex = r'[^a-zA-Z]'\n",
    "    doc = re.sub(regex, ' ', doc)\n",
    "\n",
    "    # 3. Correct Spelling\n",
    "    # blob = TextBlob(doc)\n",
    "    # doc = str(blob.correct())\n",
    "\n",
    "    # 4. Convert to lower case\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # 5. Tokenize the text\n",
    "    tokens = word_tokenize(doc)\n",
    "\n",
    "    # 6. Removal of punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # 7. Removal of stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    # 8. Stemming or Lemmatization\n",
    "    if stem:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    else:\n",
    "        tokens = [lemmatizer.lemmatize(token, wordnet_pos(token)) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd5550-35fc-4d0f-aaa9-458c83ba8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new= data_new.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaaca3a-f0a7-4fb0-b030-22fc04f47ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new['clean_text'] = data_new['text'].apply(clean)\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959bcca-d967-48ec-8671-3eb235a8f969",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa085b23-e22b-4a6b-941d-1e20c53074c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e784f1-d3b5-4a3c-89eb-e69568c0fc44",
   "metadata": {},
   "source": [
    "- Frequency distribution of Tokens/Words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02b9ac-2021-4c51-960d-693083a97728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1534b-5190-4a3e-9c45-5c608d46eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens of the corpus as an input\n",
    "# List of all token in dataset\n",
    "from nltk import WordPunctTokenizer\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a518d29-a11e-41f8-8f03-e84d9328e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=[]\n",
    "[token.extend(word_tokenize(doc)) for doc in df['text']]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523acab9-a4f6-43bd-8ff5-3b1b241cb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fcbfd-ae03-42fa-a29d-e324ce651743",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dist=FreqDist(token)\n",
    "token_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d1401-ce1d-4254-ba9d-5256748d2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dist.most_common(30) #remove stopwords and punctuations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a865938-d0ca-4943-a492-15b312a064ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tokens=[tok for tok in token_dist.most_common() if len(tok[0]) >=2]\n",
    "updated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bc7d0-e9cf-4563-b93e-fef5685613de",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tokens[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462a5f1-6344-49c0-a920-9fd2fd7a93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam\n",
    "spam=df[df['label']=='spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b84bd-6904-4aba-82c5-94cf3e6a0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham\n",
    "ham=df[df['label']=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5857e-48e0-43a5-a3f3-f875e8bcdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae29531-577d-44b9-9f42-9224dfa2ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_spam=[]\n",
    "[token_spam.extend(word_tokenize(doc)) for doc in spam['text']]\n",
    "len(token_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e99b7-677b-4565-b282-9e852a4846e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dist=FreqDist(token_spam)\n",
    "spam_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a6c9c-9baa-49e8-ac56-58ca95ff0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dist.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fbb10-185e-4037-8a45-9c58a3c44cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dict=dict(spam_dist.most_common(30))\n",
    "spam_ser=pd.Series(spam_dict)\n",
    "spam_ser.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f2d03-4171-4435-a8ab-23a5ab5ee79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_spam_tokens=[tok for tok in spam_dist.most_common() if len(tok[0])>=2]\n",
    "updated_spam_tokens[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cb69a-b7d5-4b7e-b807-cfa157b725f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dict=dict(updated_spam_tokens[:30])\n",
    "spam_ser=pd.Series(spam_dict)\n",
    "spam_ser.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdffc23-8cdc-4e4e-a874-ccc588b9e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham\n",
    "token_ham=[]\n",
    "[token_ham.extend(word_tokenize(doc)) for doc in ham['text']]\n",
    "len(token_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf203e-e07a-42e7-a1db-b68caa0330d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dist=FreqDist(token_ham)\n",
    "ham_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb67c7-b1cb-4249-a04c-118947242399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dist.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942c3bc-bb27-43c3-b063-7b0360467afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dict=dict(ham_dist.most_common(30))\n",
    "ham_ser=pd.Series(ham_dict)\n",
    "ham_ser.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eefb4ae-3402-47b0-9d59-756cfaba2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_ham_tokens=[tok for tok in ham_dist.most_common() if len(tok[0])>=2]\n",
    "updated_ham_tokens[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4019657-1e05-40b7-9b4e-3e80aca49728",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dict=dict(updated_ham_tokens[:30])\n",
    "ham_ser=pd.Series(ham_dict)\n",
    "ham_ser.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bb863-4bb3-45be-8924-3f1abc582f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_text =' '.join([doc for doc in spam['text']])\n",
    "spam_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2eb46-5f5b-469f-9782-5d616aa311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_text =' '.join([doc for doc in ham['text']])\n",
    "ham_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba705d60-d939-4663-9de3-2108653740ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f65541-0cf0-4cbc-9c8a-576c1779e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed122e6-e12a-41e0-b1e2-02304cb1641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc=WordCloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de1cef-0335-4ef3-bb17-e673d10f9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wc.generate(spam_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74792e8b-b2de-4361-ad96-ec29942ef9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wc.generate(ham_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5d53b-adf5-459a-a4f7-b738feb24c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(18,6))\n",
    "ax[0].imshow(wc.generate(spam_text))\n",
    "ax[1].imshow(wc.generate(ham_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd09b97-9b0b-41f8-9009-106e559bee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import contractions\n",
    "except:\n",
    "  !pip install contractions\n",
    "  import contractions\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc, stem = True):\n",
    "    # 1. Correct shortforms\n",
    "    # doc = contractions.fix(doc)\n",
    "\n",
    "    # 2. Clean the text using regex\n",
    "    regex = r'[^a-zA-Z]'\n",
    "    doc = re.sub(regex, ' ', doc)\n",
    "\n",
    "    # 3. Correct Spelling\n",
    "    # blob = TextBlob(doc)\n",
    "    # doc = str(blob.correct())\n",
    "\n",
    "    # 4. Convert to lower case\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # 5. Tokenize the text\n",
    "    tokens = word_tokenize(doc)\n",
    "\n",
    "    # 6. Removal of punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    # 7. Removal of stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    # 8. Stemming or Lemmatization\n",
    "    if stem:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    else:\n",
    "        tokens = [lemmatizer.lemmatize(token, wordnet_pos(token)) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0d6ee-6df0-47d8-a403-fa5fef5e93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['text']]\n",
    "y=df['label_num']\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34516b37-3a95-476c-b90b-6f7301cc9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf7b94-fa0e-4a44-9ada-e22f95b46280",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42,stratify=y)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab48719-ac99-4b1f-9d30-b33a365ebcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cc81b-a814-4529-8748-3e16ca5d0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessor - a function as an argument,it preprocesses all the documentss using the function\n",
    "#tokenizer -a function as an argument,it split ddocuments with function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fc91f-62cb-4a4e-a086-1dbaff4873aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e58d32-655d-4c0a-a7b7-6284d216f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return word_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af038cea-2aeb-4c65-a34c-18b60b41eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect=CountVectorizer(preprocessor=clean,tokenizer=tokenize)\n",
    "cvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e72f4-8405-4322-aad9-6f5621ebb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed=cvect.fit_transform(x_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2149256-2118-4457-b8ea-2af8f0a7167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa1667-f526-49b7-9ed3-f89c22c9619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train_transformed.toarray(),columns=cvect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce5230-5bc2-413d-ae39-f4fde6f1093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8e4ff-6e18-44a5-894a-95b9aa6c74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a5b45-8cb4-44fe-9509-86a108e2770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(x_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd4c8a-21d4-4887-8224-04d066caf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(x_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde3a19-c619-4eaa-8a31-191cef295c69",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add92b2-0087-4eca-b8c2-aaad09ad5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_transformed=cvect.transform(x_test['text'])\n",
    "x_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346aa713-8d98-43ee-b67e-cfb5a9edfcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(x_test_transformed)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55658332-93d7-4555-92d7-a7ebc4c56b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ebed7-c90d-4327-8c50-8f982d362207",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d9dd9-b758-43b3-bebf-aa35c0a13b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
